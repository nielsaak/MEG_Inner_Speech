{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28a2be5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8369d-b20b-4fd4-bbfe-1f8def5da852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne \n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import imblearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, permutation_test_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b558a",
   "metadata": {},
   "source": [
    "## Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392175a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_func(subject, date, raw_path, h_freq=40):\n",
    "    \n",
    "    recording_names = ['002.other_block1',\n",
    "                       '004.other_block2',\n",
    "                       '006.other_block3']\n",
    "    \n",
    "    raw_list = []\n",
    "\n",
    "    for _, recording_name in enumerate(recording_names):\n",
    "        fif_fname = recording_name[4:]\n",
    "        full_path = join(raw_path, subject, date, 'MEG', recording_name,\n",
    "                         'files', fif_fname + '.fif')\n",
    "        print(full_path)\n",
    "        raw = mne.io.read_raw(full_path, preload=True)\n",
    "        raw.info[\"bads\"] = [\"MEG0422\", \"MEG1312\"] # bad channels\n",
    "        raw.filter(l_freq=None, h_freq=h_freq, n_jobs=3)\n",
    "\n",
    "        raw_list.append(raw)\n",
    "\n",
    "    return raw_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adee1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws = read_raw_func('0112', '20230927_000000', raw_path='/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/MEG_data', h_freq = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71157337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up and fit the ICA\n",
    "ica_1 = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "ica_2 = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "ica_3 = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)\n",
    "ica_1.fit(raws[0])\n",
    "ica_2.fit(raws[1])\n",
    "ica_3.fit(raws[2])\n",
    "ica_1.plot_components()\n",
    "ica_2.plot_components()\n",
    "ica_3.plot_components()\n",
    "\n",
    "#raw.load_data()\n",
    "#ica.apply(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a96b7",
   "metadata": {},
   "source": [
    "There does not seem to be any eyeblinks or heartrate affecting the data. So we will continue without removing any of the IC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef56ea0",
   "metadata": {},
   "source": [
    "## Creating epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c212971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to look at events\n",
    "\n",
    "for i in range(3):\n",
    "    events = mne.find_events(raws[i], min_duration=0.002) ## returns a numpy array\n",
    "    mne.viz.plot_events(events) ## samples on x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eca7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs_from_raw(raw,tmin=-0.200, tmax=1.000, baseline=(None, 0), reject=None, decim=4):\n",
    "    \n",
    "    recording_names = ['002.other_block1',\n",
    "                       '004.other_block2',\n",
    "                       '006.other_block3']\n",
    "    \n",
    "    epochs_list = list()\n",
    "    for recording_index, recording_name in enumerate(recording_names):    \n",
    "        events = mne.find_events(raws[recording_index], min_duration=0.002)\n",
    "        if 'other' in recording_name: \n",
    "            event_id = dict(other_positive=21, other_negative=22,\n",
    "                            button_press=23)\n",
    "        else:\n",
    "            raise NameError('Event codes are not coded for file')\n",
    "        \n",
    "        epochs = mne.Epochs(raws[recording_index], events, event_id, tmin, tmax, baseline,\n",
    "                            preload=True, decim=decim, reject=reject, proj=True)\n",
    "        epochs.pick_types(meg=True)\n",
    "        \n",
    "        epochs_list.append(epochs)\n",
    "    \n",
    "    return epochs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe55df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating epochs\n",
    "\n",
    "epochs_list = create_epochs_from_raw(raws, tmin=-0.200, tmax=1.000, baseline=(None, 0), reject=dict(mag=4e-12, grad=4000e-13, eog=250e-6), decim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52667db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of dropped epochs\n",
    "\n",
    "# ignored_object =  epochs_list[0].drop_log[8]\n",
    "\n",
    "# [n for n, dl in enumerate(epochs_list[0].drop_log) if len(dl) and dl != ignored_object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    fig = epochs_list[i].plot_drop_log()\n",
    "    fig.savefig(f\"../data/plots/rejeted_epochs_{i}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfe8ec",
   "metadata": {},
   "source": [
    "From the first block 22 epochs was removed due to EOG1 channel. From the second block 15 epochs was removed due to EOG1 channel and 1 epoch was removed due to channel MEG2512. From the third block 30 epochs was removed due to EOG1 channel and 5 epoch was removed due to different MEG channels. By visual inspection none of the epochs were rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c10945",
   "metadata": {},
   "source": [
    "## Forward Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe22bf",
   "metadata": {},
   "source": [
    "### Looking at the co-registration and source reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96564426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SOURCE RECONSTRUCTION\n",
    "meg_path = '/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/MEG_data/0112/20230927_000000/MEG/004.other_block2/files'\n",
    "bem_path =  '/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer/0112/bem' \n",
    "subjects_dir = '/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer/'      \n",
    "raw_name = 'other_block1.fif'\n",
    "fwd_name = 'other_block1-oct-6-src-5120-fwd.fif'\n",
    "\n",
    "#%% read forward solution\n",
    "fwd = mne.read_forward_solution(join(bem_path, fwd_name))\n",
    "src = fwd['src'] # where are the sources\n",
    "trans = fwd['mri_head_t'] # what's the transformation between mri and head\n",
    "info = epochs_list[1].info # where are the sensors?\n",
    "bem_sol = fwd['sol'] # how do electric fields spread from the sources inside the head?\n",
    "bem = join(bem_path, '0112-5120-bem.fif')\n",
    "\n",
    "#%% plot source space\n",
    "src.plot(trans=trans, subjects_dir=subjects_dir)\n",
    "src.plot(trans=fwd['mri_head_t'], subjects_dir=subjects_dir, head=True,\n",
    "         skull='inner_skull')\n",
    "mne.viz.plot_alignment(info, trans=trans, subject='0112',\n",
    "                       subjects_dir=subjects_dir, src=src,\n",
    "                       bem=bem, dig=True, mri_fiducials=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b3bd6",
   "metadata": {},
   "source": [
    "### Function for actually doing source reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4975d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_source_space_data(subject, subjects_dir, epochs_list,\n",
    "                              method='MNE', lambda2=1, pick_ori='normal',\n",
    "                              label=None):\n",
    "    y = np.zeros(0)\n",
    "    for epochs in epochs_list: # get y\n",
    "        y = np.concatenate((y, epochs.events[:, 2]))\n",
    "    \n",
    "    if label is not None:\n",
    "        label_path = join(subjects_dir, subject, 'label', label)\n",
    "        label = mne.read_label(label_path)\n",
    "        \n",
    "    recording_names = ['002.other_block1',\n",
    "                       '004.other_block2',\n",
    "                       '006.other_block3']\n",
    "    for epochs_index, epochs_i in enumerate(epochs_list): ## get X\n",
    "        \n",
    "        fwd_fname = recording_names[epochs_index][4:] + '-oct-6-src-' + \\\n",
    "                    '5120-fwd.fif'\n",
    "        fwd = mne.read_forward_solution(join(subjects_dir,\n",
    "                                             subject, 'bem', fwd_fname))\n",
    "        noise_cov = mne.compute_covariance(epochs_i, tmax=0.000)\n",
    "        inv = mne.minimum_norm.make_inverse_operator(epochs_i.info,\n",
    "                                                     fwd, noise_cov)\n",
    "  \n",
    "        stcs = mne.minimum_norm.apply_inverse_epochs(epochs_i, inv, lambda2,\n",
    "                                                     method, label,\n",
    "                                                     pick_ori=pick_ori)\n",
    "\n",
    "        for stc_index, stc in enumerate(stcs):\n",
    "            this_data = stc.data\n",
    "            if stc_index == 0:\n",
    "                n_trials = len(stcs)\n",
    "                n_vertices, n_samples = this_data.shape\n",
    "                this_X = np.zeros(shape=(n_trials, n_vertices, n_samples))\n",
    "            this_X[stc_index, :, :] = this_data\n",
    "        if epochs_index == 0:\n",
    "            X = this_X\n",
    "        else:\n",
    "            X = np.concatenate((X, this_X))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94e7a8",
   "metadata": {},
   "source": [
    "## Cluster based permutation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% SIMPLE CLASSIFICATION\n",
    "\n",
    "def get_indices(y, triggers):\n",
    "    indices = list()\n",
    "    for trigger_index, trigger in enumerate(y):\n",
    "        if trigger in triggers:\n",
    "            indices.append(trigger_index)\n",
    "            \n",
    "    return indices\n",
    "\n",
    "def equalize_number_of_indices(X, y): # write this yourself\n",
    "    # np.unique(y, return_counts=True)\n",
    "\n",
    "    rus = imblearn.under_sampling.RandomUnderSampler(sampling_strategy={21: 44, 22: 44, 23: 88},random_state=42)\n",
    "    \n",
    "    rus.fit_resample(X[:,:,0], y)\n",
    "    \n",
    "    X_balanced = X[rus.sample_indices_]\n",
    "    y_balanced = y[rus.sample_indices_]\n",
    "    y_balanced_new = np.array([21 if y_balanced[i] == 22 else y_balanced[i] for i in range(len(y_balanced))])\n",
    "    return X_balanced, y_balanced, y_balanced_new\n",
    "\n",
    "def simple_classication_permutation(X, y, triggers, penalty='none', C=1.0):\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    n_samples = X.shape[2]\n",
    "    indices = get_indices(y, triggers)\n",
    "    # equalize_number_of_indices()\n",
    "    X = X[indices, :, :]\n",
    "    y = y[indices]\n",
    "    logr = LogisticRegression(penalty=penalty, C=C, solver='newton-cg')\n",
    "    sc = StandardScaler() # especially necessary for sensor space as\n",
    "                          ## magnetometers\n",
    "                          # and gradiometers are on different scales \n",
    "                          ## (T and T/m)\n",
    "    cv = StratifiedKFold()\n",
    "    \n",
    "    mean_scores = np.zeros(n_samples)\n",
    "    n_permutations = 100\n",
    "    feature_importance= np.zeros((n_features,n_samples))\n",
    "    permutation_scores=np.zeros((n_samples,n_permutations))\n",
    "    pvalues=np.zeros(n_samples)\n",
    "    \n",
    "    for sample_index in range(n_samples):\n",
    "        this_X = X[:, :, sample_index]\n",
    "        sc.fit(this_X)\n",
    "        this_X_std = sc.transform(this_X)\n",
    "        # scores = cross_val_score(logr, this_X_std, y, cv=cv)\n",
    "        scores, permutation_score, pvalue= permutation_test_score(logr, this_X_std, y, cv=cv)\n",
    "        logr.fit(this_X_std,y)\n",
    "        importances = permutation_importance(logr, this_X_std, y)\n",
    "        feature_importance[:,sample_index] = importances.importances_mean\n",
    "        mean_scores[sample_index] = np.mean(scores)\n",
    "        permutation_scores[sample_index,:]=permutation_score\n",
    "        pvalues[sample_index] = pvalue\n",
    "        if (sample_index % 10) == 0:\n",
    "            print(sample_index)\n",
    "        \n",
    "    return mean_scores, permutation_scores, pvalues, feature_importance\n",
    "\n",
    "def plot_classfication(times, mean_scores, title=None):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(times, mean_scores)\n",
    "    plt.hlines(0.50, times[0], times[-1], linestyle='dashed', color='k')\n",
    "    plt.ylabel('Proportion classified correctly')\n",
    "    plt.xlabel('Time (s)')\n",
    "    if title is None:\n",
    "        pass\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# plot function\n",
    "\n",
    "def plot_permutation_func(times, classification_scores, permutation_scores, suptitle, title, file_name, level = 0.95):\n",
    "    # Get the bottom and top percentiles of the permutation based on 'level'\n",
    "    permutation_top=np.quantile(permutation_scores,1-((1-level)/2),axis=1)\n",
    "    permutatio_bottom=np.quantile(permutation_scores,0+((1-level)/2),axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(times, classification_scores)\n",
    "    plt.fill_between(times, permutatio_bottom,permutation_top,color=\"green\", alpha=0.25)\n",
    "    plt.hlines(0.50, times[0], times[-1], linestyle='dashed', color='k')\n",
    "    plt.ylabel(f'Proportion classified correctly ({level*100}% perm. interval)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.suptitle(suptitle)\n",
    "    plt.title(title, fontsize = 10)\n",
    "\n",
    "    plt.savefig(f\"../data/plots/MEG_InSpe_{file_name}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Function that concatenates two labels and creates a new label that is the concatenation of the two\n",
    "def concatenate_labels(subject, subjects_dir, label1, label2, new_label_name):\n",
    "    # Paths\n",
    "    label1_path = join(subjects_dir, subject, 'label', label1)\n",
    "    label2_path = join(subjects_dir, subject, 'label', label2)\n",
    "    # reading labels\n",
    "    label1 = mne.read_label(label1_path)\n",
    "    label2 = mne.read_label(label2_path)\n",
    "    # concatenating labels\n",
    "    new_label = label1 + label2\n",
    "    # saving new label\n",
    "    new_label.save(join(subjects_dir, subject, 'label', new_label_name))\n",
    "\n",
    "times = epochs_list[0].times # get time points for later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961e337c",
   "metadata": {},
   "source": [
    "### Brodmann Area 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dir = '/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer/'\n",
    "\n",
    "concatenate_labels('0112', \n",
    "                   subjects_dir, \n",
    "                   'rh.BA4a_exvivo.label',\n",
    "                   'rh.BA4p_exvivo.label', \n",
    "                   'rh.BA4aBA4p_exvivo.label')\n",
    "\n",
    "concatenate_labels('0112', \n",
    "                   subjects_dir, \n",
    "                   'lh.BA4a_exvivo.label',\n",
    "                   'lh.BA4p_exvivo.label', \n",
    "                   'lh.BA4aBA4p_exvivo.label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c299370",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lh_BA4aBA4p, y = preprocess_source_space_data(subject='0112',\n",
    "                                            subjects_dir='/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer',\n",
    "                                            label='lh.BA4aBA4p_exvivo.label', \n",
    "                                            epochs_list=epochs_list) \n",
    "\n",
    "X_rh_BA4aBA4p, y = preprocess_source_space_data(subject='0112',\n",
    "                                            subjects_dir='/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer',\n",
    "                                            label='rh.BA4aBA4p_exvivo.label', \n",
    "                                            epochs_list=epochs_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f529c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BA4aBA4p = np.concatenate((X_lh_BA4aBA4p, X_rh_BA4aBA4p), axis = 1)\n",
    "\n",
    "X_BA4aBA4p_balanced, y_balanced, y_balanced_new = equalize_number_of_indices(X_BA4aBA4p, y)\n",
    "\n",
    "other_vs_response_BA4aBA4p_rh_lh = simple_classication_permutation(X_BA4aBA4p_balanced,\n",
    "                                  y_balanced_new, triggers=[21, 23],\n",
    "                                  penalty='l2', C=1e-3)\n",
    "\n",
    "plot_permutation_func(times, \n",
    "                      other_vs_response_BA4aBA4p_rh_lh[0], \n",
    "                      other_vs_response_BA4aBA4p_rh_lh[1], \n",
    "                      suptitle = \"BA4 Both Hemispheres\", \n",
    "                      title = \"Button Press vs. Inner Speech (Other-Cued)\", \n",
    "                      file_name = \"ba4\", \n",
    "                      level = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca045ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Maximum classification accuracy: {np.max(other_vs_response_BA4aBA4p_rh_lh[0])}\")\n",
    "print(f\"Maximum classification accuracy is happening at time {times[np.argmax(other_vs_response_BA4aBA4p_rh_lh[0])]}\")\n",
    "print(f\"Percentage of accuracies with p-value below .05 (between 0.3 and 0.7 seconds): {np.sum(other_vs_response_BA4aBA4p_rh_lh[2][np.where(times==0.3)[0][0]:np.where(times==0.7)[0][0]]<0.05)/np.count_nonzero(other_vs_response_BA4aBA4p_rh_lh[2][np.where(times==0.3)[0][0]:np.where(times==0.7)[0][0]])}\")\n",
    "print(f\"Percentage of accuracies with p-value below .05: {np.sum(other_vs_response_BA4aBA4p_rh_lh[2]<0.05)/np.count_nonzero(other_vs_response_BA4aBA4p_rh_lh[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5384c4",
   "metadata": {},
   "source": [
    "### Positive vs. Negative: Orbitofrontal Cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lh_orbitofrontal, y = preprocess_source_space_data(subject='0112',\n",
    "                                            subjects_dir='/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer',\n",
    "                                            label='lh.lateral_medial_orbitofrontal_exvivo.label', \n",
    "                                            epochs_list=epochs_list)  \n",
    "\n",
    "X_rh_orbitofrontal, y = preprocess_source_space_data(subject='0112',\n",
    "                                            subjects_dir='/Users/nielsaalundkrogsgaard/documents_local/MEG_Inner_Speech/data/Freesurfer',\n",
    "                                            label='rh.lateral_medial_orbitofrontal_exvivo.label', \n",
    "                                            epochs_list=epochs_list)  \n",
    "\n",
    "X_orbitofrontal = np.concatenate((X_lh_orbitofrontal, X_rh_orbitofrontal), axis = 1)\n",
    "\n",
    "pos_vs_neg_orbitofrontal = simple_classication_permutation(X_orbitofrontal,\n",
    "                                  y, triggers=[21, 22],\n",
    "                                  penalty='l2', C=1e-3)\n",
    "\n",
    "plot_permutation_func(times, \n",
    "                      pos_vs_neg_orbitofrontal[0], \n",
    "                      pos_vs_neg_orbitofrontal[1], \n",
    "                      suptitle = \"Orbitofrontal Cortex: Both Hemispheres\", \n",
    "                      title = \"Positive vs. Negative (Other-Cued)\", \n",
    "                      file_name = \"orbitofrontal\", \n",
    "                      level = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of times accuracy has a p-value below .05: {len(times[np.where(pos_vs_neg_orbitofrontal[2]<0.05)])}\")\n",
    "print(f\"Percentage of classifier p-values below .05: {np.sum(pos_vs_neg_orbitofrontal[2]<0.05)/np.count_nonzero(pos_vs_neg_orbitofrontal[2])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
